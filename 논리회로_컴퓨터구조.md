# 논리회로 / 컴퓨터구조

1. 아키텍쳐가 무엇인가
   (1) 시스템 아키텍처

   - 시스템 아키텍처란 시스템의 개념적 모형이다. 시스템의 목적을 달성하기 위해 각 구성 요소가 무엇이며 어떻게 상호작용하고 정보가 어떻게 교환되는 지를 계획하고 설명한다.
   - 시스템 전체(하드웨어와 소프트웨어를 포괄한 것)에 대한 논리적인 기능 체계와 그것을 실현하기 위한 구성 방식. 시스템의 전체적인 최적화를 목표로 하고 있다.

   (2) 컴퓨터 아키텍처 (컴퓨터 구조)

   * 컴퓨터 시스템의 기능(functionality), 조직(organization), 구현(implementation)에 대한 법칙과 방법
   * 컴퓨터 구조는 [명령어 집합 구조](https://ko.wikipedia.org/wiki/명령어_집합)(Instruction set architecture, ISA), [마이크로아키텍처](https://ko.wikipedia.org/wiki/마이크로아키텍처)(Microarchitecture) 설계, 논리 설계 및 구현

2. 폰 노이만과 하버드 아키텍쳐에 대해서 설명하시오

   <img src=".\images\architecture.jpg" alt="architecture" style="zoom:100%;" />

   - 폰 노이만 구조 : 
     - 이름 그대로 존 폰 노이만이 고안한 내장 메모리 순차처리 방식이다. 데이터 메모리와 프로그램 메모리가 구분되어 있지 않고 하나의 버스를 가지고 있는 구조를 말한다. 이 구조에서 CPU는 메모리로부터 명령을 읽고, 메모리로부터 데이터를 읽고 쓰기도 한다. 명령과 데이터는 같은 신호 버스와 메모리를 사용하기 때문에 동시에 접근하는 것은 불가능하다. (명령어를 읽을 때 데이터를 읽거나 쓸 수 없다.)
     - 폰 노이만 구조의 디지털 컴퓨터에서는 ‘저장된 프로그램’(stored-program)의 개념이 도입되었다. 이는 프로그램을 구성하는 명령어들을 임의 접근이 가능한 메모리상에 순차적으로 배열하고, 동시에 조건 분기를 무제한적으로 허용한다는 것을 뜻한다. 폰 노이만 구조에서는 같은 메모리 속에 실행코드와 데이터가 따로 구분되지 않고 함께 섞여 있다.
     - **폰 노이만 병목현상**
       - 내장 메모리 순차처리 방식으로, 데이터 메모리와 프로그램 메모리가 구분되어 있지 않고 하나의 버스를 가지고 있는 구조 때문에 CPU가 명령어와 데이터에 동시 접근할 수 없습니다. 이를 해결하고자 나타난 구조가 하버드 구조입니다.
       - 또한 메모리의 값을 읽고 쓰는 구조이기 때문에 기억장치에 병목현상이 생길 수 밖에 없습니다. 이를 해결하고자 나타난 기술에는 메모리 계층 구조나 NUMA, DMA 등이 있습니다.
   - 하버드 구조 :
     - 하버드 아키텍처(Harvard architecture)는 본래 명령용 버스와 데이터용 버스로 물리적으로 분할한 컴퓨터 아키텍처를 나타내는 용어입니다 (폰 노이만 구조와 대비시킨 용어이기도 합니다).
     - 폰노이만 구조에서는 CPU가 명령어와 데이터에 동시에 접근이 불가능해서 한번에 하나씩 처리할 수 없었던 반면에, 하버드 아키텍처의 컴퓨터에서는 명령을 메모리로부터 읽는 것과 데이터를 메모리로부터 읽는 것을 동시에 할 수 있습니다. 따라서 현재 명령의 처리를 끝내는 동시에 다음 명령을 읽어 들일 수 있어서 더 빠른 속도를 낼 수 있습니다.
     - 그렇지만 이러한 처리 속도를 높이려면 보다 많은 전기 회로가 필요합니다. 두개의 버스와 메모리를 가지게 되므로 CPU코어에서 공간을 많이 차지합니다.
   - 현대에 이르러서는 CPU의 외부적으로는 폰 노이만 구조를, 내부적으로는 하버드 구조를 적용하여 속도를 향상시킨 것이 많습니다. 그러나 이것 또한 폰노이만 구조를 기반으로 만들어진 것이기 때문에, 병목현상만 어느 정도 해결할 뿐 메모리 속의 프로그램을 순차적으로 실행하는 근본적인 구조 자체는 변하지 않습니다.

3. 데이터랑 명령어가 메모리를 공유하면 좋은 점이 무엇인가? 한개의 버스와 메모리를 가지므로 cpu 공간 차지가 적다, 또한 하버드 구조보다야 적은 회로가 필요하다.

4. 파이프라이닝이란?

   * 명령어를 순차적으로 실행하는 프로세서에 적용되는 기술로, 한 번에 하나의 명령어만 실행하는 것이 아닌 하나의 명령어가 실행되는 도중에 다른 명령어를 실행을 시작하는 식으로 동시에 여러 개의 명령어를 실행하는 기법
   * 동시에 여러개의 명령어를 처리하므로써 처리량을 올리는 것이지 각 명령어의 실행시간을 개선하지는 못한다.
   * 명령어를 세분화 할수록 처리 속도의 향상을 기대할 수 있지만, 실행할 명령 수에 비해 지나치게 단계를 세분화 하면 높은 효율성을 기대하기는 힘들다.

5. 슈퍼스칼라란?

   - 클록에 대한 throughput을 최대화하기 위해서 쓰입니다. 슈퍼 스칼라가 일반 파이프라이닝보다 더 많은 명령어를 처리할 수 있죠.
   - 슈퍼파이프라이닝은 파이프라이닝의 깊이를 증가시켜 더욱 많은 명령어를 중첩시키는 것, 슈퍼스칼라 파이프라이닝은 파이프라인을 여러 개 복제하여 사이클마다 다수의 명령어를 파이프라인에 투입하는 것.

6. 파이프라이닝을 단계를 늘리면 그만큼 빨라지는가?

   * 명령어를 세분화 할수록 처리 속도의 향상을 기대할 수 있지만, 실행할 명령 수에 비해 지나치게 단계를 세분화 하면 높은 효율성을 기대하기는 힘들다.

   * 해저드라는게 있는데 스트럭쳐럴 해저드, 데이터 해저드, 컨트롤 해저드 때문에 성능이 막 오르지는 않습니다.

7. 3가지 해저드를 각각 어떻게 해결하는가?

   * 구조적 해저드 : 프로세서의 자원이 부족해서 발생

     > 파이프라인에서 실행 중인 2개 이상의 명령어가 동일한 하드웨어 자원을 동시에 요구하기 때문에 파이프라인을 멈춰야 하는 상황

     | 클럭주기 | 1        | 2        | 3        | 4           | 5           | 6        | 7        |
     | -------- | -------- | -------- | -------- | ----------- | ----------- | -------- | -------- |
     | 명령어 1 | 가져오기 | 해석하기 | 실행하기 | 결과쓰기    |             |          |          |
     | 명령어 2 |          | 가져오기 | 해석하기 | 실행하기(1) | 실행하기(2) | 결과쓰기 |          |
     | 명령어 3 |          |          | 가져오기 | 해석하기    | 실행하기    | stall    | 결과쓰기 |
     | 명령어 4 |          |          |          | 가져오기    | stall       | 실행하기 | Stall    |

     위와 같이 명령어 2에서 실행하기가 한 클럭에 안 끝나는 경우, 명령어 3에서 결과쓰기를 수행할 때 멈춤(stall)이 발생한다.

     명령어 4에서는 해석하기 단계가 필요없는 명령어 이므로, 실행하기를 수행할 시 명령어 3에서 실행하기가 수행되고 있어 또한 멈춤이 발생한다.

     **해결 방안**: 충돌하는 자원을 추가로 제공하여 파이프라인을 재구성하거나, 예약표(Reservation table)을 이용하여 자원 충돌을 방지. 만약 레지스터 파일이나 메모리에서 충돌이 발생하면 읽기나 쓰기가 동시에 처리될 수 있도록 다중 포트화(multi-port)하거나 둘 이상으로 분할함으로써 구조적 해저드를 일부 해소

   * 데이터 해저드 : **이전 명령어의 결과를 기반으로 다음 명령이 수행될 때 파이프라인이 지연되는 경우 생기는 것**으로, 컴퓨터 파이프라인에서는 앞선 명령어에 종속성을 가질 때 데이터 해저드가 일어난다.

     > 연산할 데이터가 준비되지 않아 파이프라인을 멈춰야 하는 모든 상황이나 조건, 주로 선행 명령어가 사용하는 데이터와 후행 명령어가 사용하는 데이터 사이의 종속 관계로 인해 발생하므로 데이터 종속이라고도 한다.

     **해결 방안**:  **전방전달(forwarding)** 혹은 **우회전달(bypassing)**

     - 이것은 별도의 하드웨어를 추가하여 정상적으로는 얻을 수 없는 값을 내부 자원으로부터 일찍 받아오는 것을 의미하는데, 레지스터나 메모리에 아직 나타나지 않은 데이터를 기다리지 않고 데이터패스를 추가로 하드웨어에 연결하여 내부 버퍼로 부터 가져오는 것이다.(전방전달)-> 예로 쓰기 후 읽기 (RAW) 의 경우 ALU 에서 연산 완료된 값이 $1에 저장이 되는데 이를 바로 다음 명령어에서 읽고 사용해야 하는 경우, write 전에 ALU 에서 연산 완료된 값을 가지고 오는 것

     - 결과를 생성하는 파이프의 출력과 결과를 사용하는 파이프의 입력을 연결하는 별도의 경로를 추가하면 되는데, 이와같은 기법을 전방 전달 / 컴파일러의 도움으로 적재 명령어의 결과와 무관한 명령어의 순서를 바꾸는 기법을 지연적재라고 한다.

   * 제어 해저드 : 명령어의 실행 순서를 변경하는 Branch , Jump 등 **분기 명령어들로 인해 다른 명령어들이 실행 중에 한 명령어의 결과 값에 기반을 둔 결정을 할 필요**가 있을 때 일어난다.

     > 행할 명령어가 결정되지 않았거나 준비되지 않아서 파이프라인을 멈춰야하는 상황이나 조건

     | 클럭주기 | 1        | 2        | 3        | 4        | 5        | 6        | 7        |
     | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |
     | 명령어 1 | 가져오기 | 해석하기 | 실행하기 | 결과쓰기 |          |          |          |
     | 명령어 2 |          | stall    | Stall    | 가져오기 | 해석하기 | 실행하기 | 결과쓰기 |

     **해결 방안** :

     - Delayed Decision : 손실되는 클럭 동안 프로그램에 영향이 없는 다른 명령어 실행
     - Predict Taken / Not Taken : 명령어 분기를 예측하여 명령어 수행 / 명령어 분기 시 명령 취소 
     - Stall : 분기 방향이 결정될 때 까지 지연

   * 파이프라인 해저드는 해저드의 원인이 사라질 때까지 파이프라인에의 명령어 투입을 멈춰야 하는데 이를 파이프라인 중지(pipeline stall) 또는 파이프라인 버블 이라고 한다. 파이프라인 버블이 많아지면 성능향상에 방해가 되기 때문에 이를 위한 다양한 해결책이 필요하다. 소프트웨어적으로는 컴파일러의 도움으로 명령어의 순서를 변경하는 방법이 있고, 하드웨어적으로는 파이프라인을 다시 설계하거나 하드웨어 자원을 추가함으로써 파이프라인 버블을 해결할 수 있다.

8. 메모리 계층구조 (memory hierarchy)

   <img src="./images/memory_hi.jpg" alt="memory_hi" style="zoom:30%;" />

   S-RAM, D-RAM 과 같이 비싸고 빠르고 휘발성이 높은 메모리는 중앙처리장치에 가까이 배치하고, HDD나 Flash 메모리 같이 느리고 값싼 비휘발성 메모리는 큰 데이터를 오래도록 저장하는데 주로 사용됩니다.

9. 캐시를 사용하는 이유는?

   캐시는 메모리와 프로세서 사이에 있는 메모리 계층으로, CPU 와 주기억장치의 속도 차이로 인한 CPU의 대기 시간을 최소화 시키기 위하여 둘 사이에 설치하는 고속 반도체 메모리 이다. 주기억장치보다 엑세스 속도가 빠른 칩을 사용하지만 가격 및 제한된 공간 때문에 용량이 작다.

   * 캐시 hit : CPU가 원하는 데이터가 캐시에 있는 상태
   * 캐시 Miss : CPU가 원하는 데이터가 캐시에 없는 상태 -> 주기억 장치로 부터 데이터를 읽어온다.
   * 캐시의 적중률은 프로그램과 데이터의 지역성(locality)에 따라 달라짐
   * 용량이 커질수록 적중률이 높아지지만 비용이 증가하고, 주소 해독 및 정보 인출을 위한 주변 회로가 더 복잡해져 접근 시간이 다소 길어진다.

10. locality에는 어떤게 있지?

    * 시간적 지역성(최근), 공간적 지역성(기억장치내 인접 데이터들), 순차적 지역성(명령어 순차)

11. 멀티 코어 프로세스하고 멀티 쓰레드 프로세스 알아? 그러면 캐시는 어떻게 해?

    - 캐시는 두 코어가 공유하는게 있고 각각이 또 따로 가지고 있습니다.
    - 멀티 코어 프로세스는 core 가 2개 이상인 경우 동시에 여러 개의 프로세스를 처리하는 것입니다.
    - 멀티 쓰레드 프로세스는 한개의 프로세스 내에서 여러 개의 스레드를 가지고 일을 수행하는 것입니다. 이 스레드를이 모여 하나의 프로세스를 이룹니다. 즉, 하나의 작업을 여러개의 sub task로 분할해서 동시간에 실행되는 것처럼 수행하는 기법입니다.

12. 페이징 기법과 가상 메모리(virtual memory)

    가상 메모리 : 실제로 필요한 메모리 ex) 2GB > 메인 메모리 저장 용량(RAM) ex) 250MB

    - 이런 경우 Hard Disk 를 이용해서 넘치는 부분을 채우자 -> 하드 디스크 까지 메인 메모리의 영역을 확장해서 넓히는 개념
    - 가상 주소(virtual address)는 선 할당된 부분에 대한 부담과 느린 속도에 대한 개선을 한다.
    - 과정 : CPU 는 physical mem + virtual mem 이 합쳐진 범위의 주소(page) 할당 요청이 가능한데, 실제 물리 메모리는 이것보다 작으니까 이를, MMU가 CPU 가 요청한 메모리 주소를 실제 물리 메로리 주소(page frame)로 변환하여 찾아준다. 
      즉, 메인 메모리 공간이 4K블록씩 4개 -> 16KB 일때, 가상 메모리까지 해서 2GB라고 하면 CPU가 요청 가능한 주소 범위는 0~2G-1 이다. 여기서 CPU가 처음에 1k 번지 부터 20바이트 할당 요청 하면, MMU가 이를 변환하여 메인 메모리 첫번째 블럭을 0-4k로 할당한다. 두번째로 CPU가 36k부터 20바이트 할당 요청 하면 MMU가 이를 변환하여 두번째 블록을 원래는 4K-8K 부분이지만 36K-40K로 할당을 한다.
    - 마치 캐시와 RAM과의 관계처럼 RAM 과 HDD의 관계가 이뤄져 있다고 생각하면 쉽다. HDD 에 저장된 데이터 -> 스왑 파일

13. 페이지 테이블은 어디에 있는가?

    프로세스는 독립적인 메모리 공간을 차지하며, 시스템은 프로세스가 자신의 영역 외에는 접근할 수 없도록 막아야 한다. 프로그램을 실행하기 위해서는 메모리에 로드해 프로세스로 만들어야 한다. 이때 디스크에서 메인 메모리로 로드되기를 대기하는 곳이 input queue이다. 운영체제는 input queue에서 프로세스를 선택해 메모리에 로드한다.

    MMU는 TLB라는 캐시를 저장하고 있다. 가상주소가 물리 주소로 변환되어야할 때, TLB에서 우선 검색된다.

    해당 되는 주소가 있으면 (TLB hit) 물리주소가 리턴되고 메모리에 접근한다. 하지만, TLB에서 해당되는 주소가 없을 경우 (TLB miss) 페이지테이블에서 맵핑이 존재하는지 찾는다. 존재할 경우에 (page table hit) 이 값은 다시 TLB에 쓰이고 그 주소를 갖고 물리 주소로 변환 후, 메모리에 접근한다.

    페이지 테이블에서도 찾지 못할 경우에는 disk에서 찾게 되고 그 값을 다시 page table에 쓰이고 TLB에 쓰이고 물리주소로 변환 후 메모리에 접근한다.

    다시 정리하면, 가상 주소를 갖고 물리 주소에 접근할 때 TLB -> page table -> disk 순으로 접근한다고 생각하면 된다.

    **TLB는 processor 안에 있으며 page table에 경우 주로 메모리에 있으나 운영체제마다 다르다.**

14. 페이지 테이블에 접근하는 시간을 줄이기 위해 어떻게 하는가? TLB (13번 참고)

15. 페이지 폴트나면 어떻게 하는가? Disk 에서 값을 찾고 그 값을 다시 page table에 쓰고 TLB에 쓰이고 물리주소 변환 후 메모리에 접근 (13번 참고)

16. page fault 나면 page replacement 할 때 기억해야 되는 정보들이 뭐냐 그냥 바꿔주면 되는가?

    페이지 교체 알고리즘에 따라 다르다. 

    - FIFO -> 메모리에 올라온 지 가장 오래된 페이지를 교체한다. 이를 위해 각 페이지가 올라온 시간을 페이지에 기록하거나 페이지가 올라온 순서를 큐에 저장하는 방식을 이용한다.
    - Optimal (가장 오랫동안 사용되지 않을 것을 교체) -> 프로세스가 앞으로 사용할 페이지를 미리 알아야 한다 -> 아직 구현이 불가능 
    - LRU(가장 오래 사용되지 않은 것을 교체) -> 가장 오랫동안 사용되지 않은 페이지를 교체하는 것이니까 이를 판단할 수 있는 어떤 시그널을 기억해야 한다. 예로, 처음에 쓰일 때 1로 하고 그 다음 다른 게 쓰이면 +1 씩 하고,, 제일 숫자가 큰거를 빼는 것 같이
    - LFU (참조 횟수가 가장 적은 페이지를 교체) -> 이거는, 초기에 한 페이지 집중 참조하다가 이후 다시 참조하지 않는 경우 문제 가능성 존재 ->그때만 쓰고 계속 안쓰는데 교체가 안되니까
    - MFU (참조 횟수가 가장 많은 페이지를 교체) -> 참조 횟수가 적은 페이지가 최근에 사용된 것이라는 가정에 나온 알고리즘 
    - LFU 와 MFU는 실제 사용에 잘 쓰이지 않는다.

17. 밀리머신과 무어머신의 차이
    - 밀리 : 출력이 상태와 입력에 따라 다름
    - 무어 : 출력이 상태의 따라 다름

18. 논리식 간소화 방법 (카르노맵)

19. 메모리를 기억하는 소자에는 무엇이 있나?

    * S-RAM : 스위치를 켜거나 꺼서 0/1을 저장한 후, 필요할 때 스위치 상태를 읽을 수 있는 장치, 각 트랜지스터들의 동작상태를 유지하는데 전력이 소모되는 관계로 에너지적으로도 비싼 메모리, 그 속도가 엄청나게 빠름

    * D-RAM : Dynamic RAM 이라고 불리는 이유는 축전기에 저장된 전자들이 시간이 지나면 스르르 빠져나가기 때문에, 특정 시간 (1/100~1/10초 정도)에 한번씩 메모리에 저장된 내용을 다시 적어줘야 합니다. 이를 메모리를 리프레시(Refresh) 한다. 중앙연산장치에 직접 연결되어 데이터를 주고 받는 메모리로 쓰일 수 있는 것입니다. 요즘의 랩탑이나 데스크탑의 ‘메모리용량’이라고 하면 보통 이 DRAM의 용량을 말하며, 4~32GB 정도가 개인용 컴퓨터에 주로 사용되는 용량

      > S-RAM과 D-RAM은 전기 신호 자체가 0과 1을 구분하는데 사용되기 때문에, 전력 공급이 중단되면 더 이상 데이터가 날아가 버립니다. 휘발성이 높은 메모리

    * Magnetic HDD: 자석의 원리를 이용해서, 데이터를 쓰고 지우는 Magnetic HDD입니다. 우리가 하드디스크로 알고 있는 아래 사진이 그 일반적 형태입니다.

      > 자석들은 한 번 N극, S극이 정해지면 오랜 시간동안 그 성질을 유지하기 때문에 컴퓨터가 꺼져도 데이터를 그대로 유지할 수 있습니다. 비휘발성

    * NAND-Flash: NAND 플래시 메모리에 대해서 알아보겠습니다. 플래시 메모리는 USB나 SSD 등에서 데이터를 저장하는 용도로 사용

20. 

21. 

22. 

23. 



# 출처

7. https://happy-coding-day.tistory.com/49 , https://jokerkwu.tistory.com/120, http://blog.skby.net/%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%ED%95%B4%EC%A0%80%EB%93%9C-%EB%B0%8F-%ED%95%B4%EA%B2%B0%EB%B0%A9%EC%95%88/

12. https://www.youtube.com/watch?v=p1CTX5L_loc
13. https://about-myeong.tistory.com/35

19. https://steemit.com/kr-science/@doctoreecs/5tmffh